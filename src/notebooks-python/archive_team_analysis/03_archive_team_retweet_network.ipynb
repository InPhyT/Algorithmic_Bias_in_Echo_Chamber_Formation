{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n", 
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old try #1\n",
    "```python\n",
    "print(len(retweet_network))\n",
    "print(retweet_network[4])\n",
    "print(np.shape([len(dct[\"retweeted_users_ids\"]) > 2 for dct in retweet_network]))\n",
    "print(sum([len(dct[\"retweeted_users_ids\"]) > 4 for dct in retweet_network]))\n",
    "\n",
    "with open(r\"F:\\TwitterUsers\\archiveTeam\\processed_files\\retweet_network.txt\",\"rb\") as f:\n",
    "    retweet_network = pickle.load(f)\n",
    "    f.close()\n",
    "    \n",
    "    \n",
    "with open(r\"F:\\TwitterUsers\\archiveTeam\\saved_objs\\10\\objs_0.txt\",\"rb\") as f:\n",
    "    day = pickle.load(f)\n",
    "    f.close()\n",
    "    \n",
    "print(day[0])\n",
    "with open(r\"F:\\TwitterUsers\\archiveTeam\\processed_files\\unsubscribed_users.txt\",\"rb\") as f:\n",
    "    unsubscribed_users = set(pickle.load(f))\n",
    "    f.close()\n",
    "\n",
    "print(unsubscribed_users[1])\n",
    "with open(r\"F:\\TwitterUsers\\archiveTeam\\processed_files\\ok_users.txt\",\"rb\") as f:\n",
    "    ok_users = set(pickle.load(f))\n",
    "    f.close()\n",
    "\n",
    "print(ok_users[2])\n",
    "```\n",
    "\n",
    "Old try #2\n",
    "```python\n",
    "%%time\n",
    "with open(r\"F:\\TwitterUsers\\archiveTeam\\saved_objs\\01\\objs_0.txt\",\"rb\") as f:\n",
    "    day0_lst = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "with open(r\"F:\\TwitterUsers\\archiveTeam\\processed_files\\hashtags_3.txt\", \"rb\") as f:\n",
    "    hashtags = set(pickle.load(f))\n",
    "    f.close()\n",
    "print(len(hashtags))\n",
    "day0_csv = pd.DataFrame(day0_lst).drop(labels = [\"tweet_created_at\",\"followers_count\",\"friends_count\",\"statuses_count\"], axis  = 1)\n",
    "print(len(day0_csv))\n",
    "day0_csv[\"retweeted_tweet_id\"] = day0_csv[\"retweeted_tweet_id\"].apply(encapsulate)\n",
    "day0_csv[\"retweeted_user_id\"] = day0_csv[\"retweeted_user_id\"].apply(encapsulate)\n",
    "day0_csv= day0_csv[ get_lists_indices(day0_csv[\"tweet_id\"])]\n",
    "day0_csv.reset_index(inplace = True, drop = True)\n",
    "day0_csv = day0_csv[select_by_hashtags(day0_csv[\"hashtags\"])]\n",
    "print(len(day0_csv))\n",
    "day0_csv_agg = day0_csv.groupby([\"user_id\",\"profile_created_at\"], as_index = False).agg({\"retweeted_tweet_id\":\"sum\",\"retweeted_user_id\":\"sum\",\"hashtags\":\"sum\"})\n",
    "day0_csv_agg.head(50)\n",
    "#print(len(day0_csv_agg))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lists_indices(series):\n",
    "    return [type(elem) != list for elem in series  ]\n",
    "\n",
    "def reduce_extend(series):\n",
    "    return reduce(lambda x,y: x.extend(y), series)\n",
    "\n",
    "def encapsulate(x):\n",
    "    if type(x) == list:\n",
    "        return x\n",
    "    else:\n",
    "        return [x]\n",
    "    \n",
    "def isNone(series):\n",
    "    return [x is None for x in series]\n",
    "\n",
    "def select_by_hashtags(series):\n",
    "    return [not set([hashtag.lower() for hashtag in lst]).isdisjoint(hashtags) for lst in series]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load paths and hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330\n",
      "6948\n"
     ]
    }
   ],
   "source": [
    "listOfFiles = list()\n",
    "for (dirpath, dirnames, filenames) in os.walk(r\"G:\\TwitterUsers\\saved_objs_withKeywords\"):\n",
    "    listOfFiles += [os.path.join(dirpath, file) for file in filenames]\n",
    "total = len(listOfFiles)\n",
    "print(total)\n",
    "\n",
    "with open(r\"G:\\TwitterUsers\\processed_files\\hashtags\\hashtags_1_filtered.txt\", \"rb\") as f:\n",
    "    hashtags = set(pickle.load(f))\n",
    "    f.close()\n",
    "print(len(hashtags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(r\"G:\\TwitterUsers\\saved_objs_withKeywords\\11\\objs_0.txt\",\"rb\") as f:\n",
    "#     day_csv = pd.DataFrame(pickle.load(f)).drop(labels = [\"tweet_created_at\",\"followers_count\",\"friends_count\",\"statuses_count\",\"favourites_count\",\"text\"], axis  = 1)\n",
    "#     f.close()\n",
    "# day_csv.head()\n",
    "# df = pd.DataFrame()\n",
    "# day_csv[\"retweeted_tweet_id\"] = day_csv[\"retweeted_tweet_id\"].apply(encapsulate)\n",
    "# day_csv[\"retweeted_user_id\"] = day_csv[\"retweeted_user_id\"].apply(encapsulate)\n",
    "# day_csv= day_csv[ get_lists_indices(day_csv[\"tweet_id\"])]\n",
    "# day_csv = day_csv[select_by_hashtags(day_csv[\"hashtags\"])]\n",
    "# df = df.append(day_csv)\n",
    "# df = df.groupby([\"user_id\",\"profile_created_at\"] ,as_index = False).agg({\"retweeted_tweet_id\":\"sum\",\"retweeted_user_id\":\"sum\",\"hashtags\":\"sum\"})\n",
    "# df.reset_index(inplace = True, drop = True)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# day_csv[\"retweeted_tweet_id\"] = day_csv[\"retweeted_tweet_id\"].apply(encapsulate)\n",
    "# day_csv[\"retweeted_user_id\"] = day_csv[\"retweeted_user_id\"].apply(encapsulate)\n",
    "# day_csv= day_csv[ get_lists_indices(day_csv[\"tweet_id\"])]\n",
    "# day_csv = day_csv[select_by_hashtags(day_csv[\"hashtags\"])]\n",
    "# my_df = pd.DataFrame({\"a\":[[],[12]],\"b\":[[1,2,3],[1,2,3,4]],\"c\":[[1],[8,9]]})\n",
    "# my_df\n",
    "# my_df[\"d\"] = my_df[\"a\"]+my_df[\"b\"]+my_df[\"c\"]\n",
    "# my_df\n",
    "# day_csv.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process and save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 121 day(s) out of 330 , len(df) = 21020\r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.DataFrame()\n",
    "i = 0\n",
    "save_path = r\"G:\\TwitterUsers\\processed_files\\retweet_network\\retweet_network.npy\"\n",
    "backup_path = r\"G:\\TwitterUsers\\processed_files\\retweet_network\\backup\\retweet_network.npy\"\n",
    "for path in  listOfFiles:\n",
    "    with open(path,\"rb\") as f:\n",
    "        \n",
    "        day_csv = pd.DataFrame(pickle.load(f)).drop(labels = [\"tweet_created_at\",\"followers_count\",\"friends_count\",\"statuses_count\",\"favourites_count\",\"text\"], axis  = 1)\n",
    "        f.close()\n",
    "    #day0_csv = pd.DataFrame(day0_lst).drop(labels = [\"tweet_created_at\",\"followers_count\",\"friends_count\",\"statuses_count\"], axis  = 1)\n",
    "    #print(len(day0_csv))\n",
    "    day_csv[\"retweeted_tweet_id\"] = day_csv[\"retweeted_tweet_id\"].apply(encapsulate)\n",
    "    day_csv[\"retweeted_user_id\"]  = day_csv[\"retweeted_user_id\"].apply(encapsulate)\n",
    "    day_csv = day_csv[ get_lists_indices(day_csv[\"tweet_id\"])]\n",
    "    #day_csv.reset_index(inplace = True, drop = True)\n",
    "    day_csv = day_csv[select_by_hashtags(day_csv[\"hashtags\"])]\n",
    "#     try:\n",
    "    df = df.append(day_csv)\n",
    "#     except:\n",
    "#         df.drop(labels = [\"user_mentions\",\"replied_to_tweet_id\",\"replied_to_user_id\"])\n",
    "#         df = df.append(day_csv)\n",
    "    df = df.groupby([\"user_id\",\"profile_created_at\"] ,as_index = False).agg({\"retweeted_tweet_id\":\"sum\",\"retweeted_user_id\":\"sum\",\"hashtags\":\"sum\"}) #,\"user_mentions\":\"sum\" (teh columns not specified in agg are removed)\n",
    "    #df[\"interacted_users_ids\"] = day_csv[\"retweeted_user_id\"] + day_csv[\"user_mentions\"]\n",
    "    df.reset_index(inplace = True, drop = True)\n",
    "    i += 1\n",
    "    print(\"done\", i,\"day(s) out of\", total, \", len(df) =\",len(df), end = \"\\r\")\n",
    "    if i%10 == 0:\n",
    "        print(\"saving...\", end = \"\\r\")\n",
    "        df_np = df.to_numpy()\n",
    "        np.save(save_path, df_np)\n",
    "        np.save(backup_path, df_np)\n",
    "        \n",
    "print(\"last saving...\")\n",
    "df_np = df.to_numpy()\n",
    "np.save(save_path, df_np)\n",
    "np.save(backup_path, df_np)\n",
    "    #print(len(day0_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useless, all data was already saved. Do NOT uncomment\n",
    "# save_path = r\"F:\\TwitterUsers\\archiveTeam\\retweet_network\\retweet_network1.npy\"\n",
    "# backup_path = r\"F:\\TwitterUsers\\archiveTeam\\retweet_network\\backup\\retweet_network1.npy\"\n",
    "# df_np = df.to_numpy()\n",
    "# np.save(save_path, df_np)\n",
    "# np.save(backup_path, df_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reload the numpy array and convert it to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retweet_network_np = np.load(r\"F:\\TwitterUsers\\archiveTeam\\retweet_network\\retweet_network.npy\", allow_pickle = True)\n",
    "# retweet_network_csv = pd.DataFrame(retweet_network_np,columns = [\"user_id\",\t\"profile_created_at\",\t\"retweeted_tweet_id\",\t\"retweeted_user_id\",\t\"hashtags\"] )\n",
    "# print(retweet_network_np.shape)\n",
    "# retweet_network_csv.head(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
