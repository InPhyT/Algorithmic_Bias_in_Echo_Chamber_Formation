{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, r\"Q:\\IlMIoDrive\\magistrale\\1anno\\terzo_periodo\\MAS\\analysis\")\n",
    "from importlib import reload\n",
    "import credentials as cr\n",
    "import Econophysics as Ec\n",
    "Ec = reload(Ec)\n",
    "cr = reload(cr)\n",
    "import tweepy\n",
    "from threading import Thread\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from datetime import datetime,timezone\n",
    "import time\n",
    "\n",
    "from collections import Counter\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt \n",
    "from strawberryfields.apps import subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161559\n"
     ]
    }
   ],
   "source": [
    "with open(r\"G:\\TwitterUsers\\processed_files\\AT_thread_output\\ok_users.txt\", \"rb\") as f: #C:\\Econophysics\\TwitterUsers\\archiveTeam\\processed_files  # r\"F:\\TwitterUsers\\archiveTeam\\processed_files\\ok_users.txt\"\n",
    "    ok_users = pickle.load(f)\n",
    "    f.close()\n",
    "    \n",
    "print(len(ok_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Initialization\"\n",
    "path_start_rtwt = r\"G:\\TwitterUsers\\processed_files\\Initialization_RTWT_output_mentions_up\\threading_objs\\\\\" +name+\"_retweet_objs_\" \n",
    "rtwt_threads = Ec.get_threads(n_threads = 30, thread = Ec.TwitterThreadRTWT, path_start = path_start_rtwt , path_end = \".txt\", ids  = ok_users, apps = cr.apps,resource = [\"resources\",\"statuses\",'/statuses/user_timeline'],restart  = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread0 started. Downloading user objects from user_id 122159104 to 369640690 so we start from index 0 \n",
      "\n",
      "thread1 started. Downloading user objects from user_id 386942196 to 52463688 so we start from index 0 \n",
      "\n",
      "thread2 started. Downloading user objects from user_id 162039881 to 60345472 so we start from index 0 \n",
      "\n",
      "thread3 started. Downloading user objects from user_id 113298560 to 794890453 so we start from index 0 \n",
      "\n",
      "thread4 started. Downloading user objects from user_id 198250710 to 431052166 so we start from index 0 \n",
      "\n",
      "thread5thread6 started. Downloading user objects from user_id 231315095 to 343006031 so we start from index 0  \n",
      "\n",
      " started. Downloading user objects from user_id 338253194 to 247568021 so we start from index 0 \n",
      "\n",
      "thread7 started. Downloading user objects from user_id 512875346 to 618274386 so we start from index 0 \n",
      "\n",
      "thread8 started. Downloading user objects from user_id 534912601 to 17457867 so we start from index 0 \n",
      "\n",
      "thread10 started. Downloading user objects from user_id 184198463 to thread11599451524 so we start from index 0 \n",
      "\n",
      " started. Downloading user objects from user_id 702211976 to 77277787 so we start from index 0 \n",
      "\n",
      "thread9 started. Downloading user objects from user_id 262300364 to 78816574 so we start from index 0 \n",
      "\n",
      "thread13 started. Downloading user objects from user_id 30109311thread12  started. Downloading user objects from user_id 427502172 to 543911550 so we start from index 0 \n",
      "\n",
      "to 352564011 so we start from indexthread14thread15 0 \n",
      "\n",
      "  started. Downloading user objects from user_id 173274940 to 264518629 so we start from index 0 \n",
      "\n",
      "started. Downloading user objects from user_id 56865581 to 581171002 so we start from index 0 \n",
      "\n",
      "thread16 started. Downloading user objects from user_id 416562151 to 34898262 so we start from index 0 \n",
      "\n",
      "thread17 started. Downloading user objects from user_id 531923290 to 301254504 so we start from index 0 \n",
      "\n",
      "thread18 started. Downloading user objects from user_id 541378415 to 29690941 so we start from index 0 \n",
      "\n",
      "thread19 started. Downloading user objects from user_id 102042692 to 17650170 so we start from index 0 \n",
      "\n",
      "thread20 started. Downloading user objects from user_id 33903103 to 741709550 so we start from index 0thread21 started. Downloading user objects from user_id 605918959 to 33413858thread22 \n",
      "\n",
      " thread23so we start from index 0 \n",
      "\n",
      " started. Downloading user objects from user_id 396762986 to 249455660 so we start from index 0 \n",
      "\n",
      " started. Downloading user objects from user_id 591256290 to 14557032 so we start from index 0 \n",
      "\n",
      "thread24thread25  started. Downloading user objects from user_id 446605315 to 227470554 so we start from index 0 \n",
      "\n",
      "started. Downloading user objects from user_idthread26 18244654 to 126789634 so we start from index 0 \n",
      "\n",
      " started. Downloading user objects from user_id 437185756 to 24588870 so we start from index 0 \n",
      "\n",
      "thread27 started. Downloading user objects from user_id 376386119 to 725579442 so we start from index 0 \n",
      "\n",
      "thread28thread29 started. Downloading user objects from user_id 333429444 to 44564478 so we start from index 0 \n",
      "\n",
      " started. Downloading user objects from user_id 17790642 to 716683969 so we start from index 0 \n",
      "\n",
      "thread10 FINISHED!!!  5295  retweets sets out of 5386 total. Currently using with app number 0 and the last user_id was 174098184 : downloaded  1354  retweets sets out of 5386 total. Currently using with app number 0 and the last user_id was 287331879 total. Currently using with app number 0 and the last user_id was 789609068\n",
      "\n",
      "thread1thread29 FINISHED!!! retweets sets out of 5386 total. Currently using with app number 0 and the last user_id was 339249161\n",
      "\n",
      "thread1 : downloaded thread7 FINISHED!!!  out of 5386 total. Currently using with app number 0 and the last user_id was 28346387\n",
      "\n",
      "thread1 FINISHED!!!   5386  retweets sets out of 5386 total. Currently using with app number 0 and the last user_id was 524636881\n",
      "\n",
      "thread8 FINISHED!!! \n",
      "\n",
      "thread22 FINISHED!!! \n",
      "\n",
      "thread12 FINISHED!!! \n",
      "\n",
      "thread2 FINISHED!!! \n",
      "\n",
      "thread14 FINISHED!!! \n",
      "\n",
      "thread5 FINISHED!!! \n",
      "\n",
      "thread19 FINISHED!!! \n",
      "\n",
      "thread0 FINISHED!!! \n",
      "\n",
      "thread3 FINISHED!!! \n",
      "\n",
      "thread4 FINISHED!!! \n",
      "\n",
      "thread13 FINISHED!!! \n",
      "\n",
      "thread27 FINISHED!!! \n",
      "\n",
      "thread20 thread25 FINISHED!!! \n",
      "\n",
      "FINISHED!!! \n",
      "\n",
      "thread17 FINISHED!!! \n",
      "\n",
      "thread21 FINISHED!!! \n",
      "\n",
      "thread9 FINISHED!!! \n",
      "\n",
      "thread26 FINISHED!!! \n",
      "\n",
      "thread11 FINISHED!!! \n",
      "\n",
      "thread6 FINISHED!!! \n",
      "\n",
      "thread24 FINISHED!!! \n",
      "\n",
      "thread18 FINISHED!!! \n",
      "\n",
      "thread16 FINISHED!!! \n",
      "\n",
      "thread28 FINISHED!!! \n",
      "\n",
      "thread15 FINISHED!!! \n",
      "\n",
      "thread23 FINISHED!!! \n",
      "\n",
      "Wall time: 56min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Ec.start_threads(rtwt_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading...\n",
      "concatenating\n",
      "saving\n"
     ]
    }
   ],
   "source": [
    "Ec.objs_txt_unifier(threading_folder =r\"G:\\TwitterUsers\\processed_files\\Initialization_RTWT_output_mentions_up\\threading_objs\" , destination_folder = r\"G:\\TwitterUsers\\processed_files\\Initialization_RTWT_output_mentions_up\", name = \"Initialization_retweet_network_mentions_up_14_10\",mode = \"a\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 945\n"
     ]
    }
   ],
   "source": [
    "objs = np.load(r\"G:\\TwitterUsers\\processed_files\\Initialization_RTWT_output_mentions_up\\Initialization_retweet_network_mentions_up_14_10.npy\", allow_pickle = True)\n",
    "len(objs)\n",
    "#objs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retweet_network = np.load(r\"F:\\TwitterUsers\\archiveTeam\\Streamer_archiveTeam\\user_timeline\\Initialization_retweet_network.npy\", allow_pickle = True)\n",
    "# print(len(retweet_network))\n",
    "# nodes = set([user[\"user_id\"] for user in retweet_network])\n",
    "# print(len(nodes))\n",
    "# all_edges = [(user[\"user_id\"], user[\"retweeted_users_ids\"][i]) for user in retweet_network for i in range(len(user[\"retweeted_users_ids\"])) ] \n",
    "# print(len(all_edges))\n",
    "# print(all_edges[0])\n",
    "# edge_list = [tup for tup in all_edges if tup[1] in nodes]\n",
    "# len(edge_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# retweet_counter = dict(Counter(edge_list))\n",
    "# weighted_edge_list = [(*list(retweet_counter.keys())[i], list(retweet_counter.values())[i]) for i in range(len(retweet_counter ))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retweet_network = nx.DiGraph()\n",
    "# #retweet_network.add_nodes_from(nodes)\n",
    "# retweet_network.add_weighted_edges_from(weighted_edge_list)\n",
    "# retweet_network.name = \"retweet network\"\n",
    "# # Show the basic attributes of the graph\n",
    "# print(nx.info(retweet_network))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# dense1 = subgraph.search([retweet_network.to_undirected()], retweet_network.to_undirected(), 100, 101, max_count=30)\n",
    "# dense1\n",
    "# sub_100 = retweet_network.subgraph(dense1[100][0][1])\n",
    "# with open(r\"F:\\TwitterUsers\\archiveTeam\\Streamer_archiveTeam\\densest\\densest.txt\", \"wb\") as f:\n",
    "#     pickle.dump(dense1,f)\n",
    "#     f.close()\n",
    "# type(dense1)\n",
    "# dense2 = pickle.load(r\"F:\\TwitterUsers\\archiveTeam\\Streamer_archiveTeam\\densest\\densest.txt\")\n",
    "# my_dense =[]\n",
    "# for boh in dense:\n",
    "#     my_dense.append(boh)\n",
    "# my_dense"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
